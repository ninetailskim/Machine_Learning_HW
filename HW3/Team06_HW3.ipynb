{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "(26962, 784)\n",
      "(26962,)\n",
      "(2442, 784)\n",
      "(2442,)\n",
      "(4861, 784)\n",
      "(4861,)\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5\n",
    "\n",
    "print(X_train2_full.shape)\n",
    "print(y_train2_full.shape)\n",
    "print(X_valid2_full.shape)\n",
    "print(y_valid2_full.shape)\n",
    "print(X_test2.shape)\n",
    "print(y_test2.shape)\n",
    "train_num = X_train2_full.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1\n",
    "### exclude their variables from the optimizer's list of trainable variables, keeping only the output layer's trainable variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the checkpoint weights from HW2,then assign the tensor&operation based on the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./Team06_HW2.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"pred:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only let the 'FC' (softmax layer) trainable,freeze the other 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"FC\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply early stop on training then save the model as HW3_1, test accuracy:0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Team06_HW2\n",
      "0\tValidation loss: 2.914337\tBest loss: 2.914337\tAccuracy: 34.67%\n",
      "1\tValidation loss: 2.186097\tBest loss: 2.186097\tAccuracy: 34.67%\n",
      "2\tValidation loss: 2.610965\tBest loss: 2.186097\tAccuracy: 36.00%\n",
      "3\tValidation loss: 2.514665\tBest loss: 2.186097\tAccuracy: 29.33%\n",
      "4\tValidation loss: 2.171296\tBest loss: 2.171296\tAccuracy: 36.00%\n",
      "5\tValidation loss: 3.188393\tBest loss: 2.171296\tAccuracy: 42.00%\n",
      "6\tValidation loss: 2.123855\tBest loss: 2.123855\tAccuracy: 42.00%\n",
      "7\tValidation loss: 2.242008\tBest loss: 2.123855\tAccuracy: 40.67%\n",
      "8\tValidation loss: 2.226936\tBest loss: 2.123855\tAccuracy: 38.00%\n",
      "9\tValidation loss: 1.853105\tBest loss: 1.853105\tAccuracy: 45.33%\n",
      "10\tValidation loss: 1.978021\tBest loss: 1.853105\tAccuracy: 38.00%\n",
      "11\tValidation loss: 1.769349\tBest loss: 1.769349\tAccuracy: 36.00%\n",
      "12\tValidation loss: 2.105936\tBest loss: 1.769349\tAccuracy: 42.67%\n",
      "13\tValidation loss: 2.169199\tBest loss: 1.769349\tAccuracy: 46.67%\n",
      "14\tValidation loss: 2.335070\tBest loss: 1.769349\tAccuracy: 48.00%\n",
      "15\tValidation loss: 1.713899\tBest loss: 1.713899\tAccuracy: 44.67%\n",
      "16\tValidation loss: 1.857956\tBest loss: 1.713899\tAccuracy: 43.33%\n",
      "17\tValidation loss: 1.656798\tBest loss: 1.656798\tAccuracy: 43.33%\n",
      "18\tValidation loss: 2.050857\tBest loss: 1.656798\tAccuracy: 45.33%\n",
      "19\tValidation loss: 2.218656\tBest loss: 1.656798\tAccuracy: 49.33%\n",
      "20\tValidation loss: 1.894102\tBest loss: 1.656798\tAccuracy: 42.67%\n",
      "21\tValidation loss: 1.750635\tBest loss: 1.656798\tAccuracy: 46.00%\n",
      "22\tValidation loss: 1.724702\tBest loss: 1.656798\tAccuracy: 49.33%\n",
      "23\tValidation loss: 1.693608\tBest loss: 1.656798\tAccuracy: 50.00%\n",
      "24\tValidation loss: 1.589475\tBest loss: 1.589475\tAccuracy: 47.33%\n",
      "25\tValidation loss: 1.653946\tBest loss: 1.589475\tAccuracy: 51.33%\n",
      "26\tValidation loss: 1.711038\tBest loss: 1.589475\tAccuracy: 55.33%\n",
      "27\tValidation loss: 1.668221\tBest loss: 1.589475\tAccuracy: 55.33%\n",
      "28\tValidation loss: 1.781596\tBest loss: 1.589475\tAccuracy: 50.67%\n",
      "29\tValidation loss: 1.632541\tBest loss: 1.589475\tAccuracy: 46.67%\n",
      "30\tValidation loss: 1.678179\tBest loss: 1.589475\tAccuracy: 52.67%\n",
      "31\tValidation loss: 1.963775\tBest loss: 1.589475\tAccuracy: 50.67%\n",
      "32\tValidation loss: 1.607252\tBest loss: 1.589475\tAccuracy: 55.33%\n",
      "33\tValidation loss: 1.746944\tBest loss: 1.589475\tAccuracy: 52.67%\n",
      "34\tValidation loss: 1.835172\tBest loss: 1.589475\tAccuracy: 55.33%\n",
      "35\tValidation loss: 1.656879\tBest loss: 1.589475\tAccuracy: 56.67%\n",
      "36\tValidation loss: 1.763245\tBest loss: 1.589475\tAccuracy: 60.00%\n",
      "37\tValidation loss: 2.046999\tBest loss: 1.589475\tAccuracy: 54.00%\n",
      "38\tValidation loss: 1.755006\tBest loss: 1.589475\tAccuracy: 54.00%\n",
      "39\tValidation loss: 1.755757\tBest loss: 1.589475\tAccuracy: 62.00%\n",
      "40\tValidation loss: 1.819952\tBest loss: 1.589475\tAccuracy: 51.33%\n",
      "41\tValidation loss: 1.807168\tBest loss: 1.589475\tAccuracy: 55.33%\n",
      "42\tValidation loss: 1.727088\tBest loss: 1.589475\tAccuracy: 56.67%\n",
      "43\tValidation loss: 1.979931\tBest loss: 1.589475\tAccuracy: 56.67%\n",
      "44\tValidation loss: 1.604177\tBest loss: 1.589475\tAccuracy: 62.67%\n",
      "Early stopping!\n",
      "Total training time: 1.6s\n",
      "INFO:tensorflow:Restoring parameters from ./Team06_HW3_1\n",
      "Final test accuracy: 52.99%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./Team06_HW2\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    t0 = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./Team06_HW3_1\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./Team06_HW3_1\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "### compute the output of the top frozen layer at the beginning (both for the training set and the validation set), and we cache it. This makes training roughly faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"h5:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test accuracy:0.5 though fast training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Team06_HW2\n",
      "0\tValidation loss: 3.262501\tBest loss: 3.262501\tAccuracy: 35.33%\n",
      "1\tValidation loss: 2.061656\tBest loss: 2.061656\tAccuracy: 34.67%\n",
      "2\tValidation loss: 2.407110\tBest loss: 2.061656\tAccuracy: 35.33%\n",
      "3\tValidation loss: 2.271895\tBest loss: 2.061656\tAccuracy: 30.67%\n",
      "4\tValidation loss: 2.096857\tBest loss: 2.061656\tAccuracy: 38.67%\n",
      "5\tValidation loss: 2.535693\tBest loss: 2.061656\tAccuracy: 35.33%\n",
      "6\tValidation loss: 2.027433\tBest loss: 2.027433\tAccuracy: 34.67%\n",
      "7\tValidation loss: 2.627248\tBest loss: 2.027433\tAccuracy: 45.33%\n",
      "8\tValidation loss: 2.194199\tBest loss: 2.027433\tAccuracy: 36.67%\n",
      "9\tValidation loss: 1.899158\tBest loss: 1.899158\tAccuracy: 41.33%\n",
      "10\tValidation loss: 1.783677\tBest loss: 1.783677\tAccuracy: 45.33%\n",
      "11\tValidation loss: 1.738483\tBest loss: 1.738483\tAccuracy: 44.00%\n",
      "12\tValidation loss: 1.756335\tBest loss: 1.738483\tAccuracy: 45.33%\n",
      "13\tValidation loss: 1.816615\tBest loss: 1.738483\tAccuracy: 46.00%\n",
      "14\tValidation loss: 2.183896\tBest loss: 1.738483\tAccuracy: 51.33%\n",
      "15\tValidation loss: 1.827546\tBest loss: 1.738483\tAccuracy: 48.00%\n",
      "16\tValidation loss: 1.811075\tBest loss: 1.738483\tAccuracy: 48.00%\n",
      "17\tValidation loss: 1.887293\tBest loss: 1.738483\tAccuracy: 42.67%\n",
      "18\tValidation loss: 1.941147\tBest loss: 1.738483\tAccuracy: 44.67%\n",
      "19\tValidation loss: 1.869947\tBest loss: 1.738483\tAccuracy: 54.00%\n",
      "20\tValidation loss: 1.763508\tBest loss: 1.738483\tAccuracy: 44.67%\n",
      "21\tValidation loss: 1.669035\tBest loss: 1.669035\tAccuracy: 44.67%\n",
      "22\tValidation loss: 2.015956\tBest loss: 1.669035\tAccuracy: 51.33%\n",
      "23\tValidation loss: 1.831821\tBest loss: 1.669035\tAccuracy: 49.33%\n",
      "24\tValidation loss: 1.830113\tBest loss: 1.669035\tAccuracy: 46.00%\n",
      "25\tValidation loss: 1.568419\tBest loss: 1.568419\tAccuracy: 48.00%\n",
      "26\tValidation loss: 1.877494\tBest loss: 1.568419\tAccuracy: 44.00%\n",
      "27\tValidation loss: 1.943663\tBest loss: 1.568419\tAccuracy: 52.00%\n",
      "28\tValidation loss: 1.885237\tBest loss: 1.568419\tAccuracy: 48.67%\n",
      "29\tValidation loss: 1.941146\tBest loss: 1.568419\tAccuracy: 50.00%\n",
      "30\tValidation loss: 1.592007\tBest loss: 1.568419\tAccuracy: 52.67%\n",
      "31\tValidation loss: 2.157623\tBest loss: 1.568419\tAccuracy: 50.00%\n",
      "32\tValidation loss: 1.711319\tBest loss: 1.568419\tAccuracy: 54.00%\n",
      "33\tValidation loss: 1.677992\tBest loss: 1.568419\tAccuracy: 62.00%\n",
      "34\tValidation loss: 2.539213\tBest loss: 1.568419\tAccuracy: 44.00%\n",
      "35\tValidation loss: 1.646034\tBest loss: 1.568419\tAccuracy: 55.33%\n",
      "36\tValidation loss: 1.957572\tBest loss: 1.568419\tAccuracy: 61.33%\n",
      "37\tValidation loss: 2.146915\tBest loss: 1.568419\tAccuracy: 57.33%\n",
      "38\tValidation loss: 1.781795\tBest loss: 1.568419\tAccuracy: 49.33%\n",
      "39\tValidation loss: 1.620775\tBest loss: 1.568419\tAccuracy: 54.00%\n",
      "40\tValidation loss: 1.713292\tBest loss: 1.568419\tAccuracy: 52.00%\n",
      "41\tValidation loss: 1.704068\tBest loss: 1.568419\tAccuracy: 54.67%\n",
      "42\tValidation loss: 1.704513\tBest loss: 1.568419\tAccuracy: 57.33%\n",
      "43\tValidation loss: 1.896886\tBest loss: 1.568419\tAccuracy: 50.00%\n",
      "44\tValidation loss: 1.716705\tBest loss: 1.568419\tAccuracy: 58.67%\n",
      "45\tValidation loss: 1.682025\tBest loss: 1.568419\tAccuracy: 57.33%\n",
      "Early stopping!\n",
      "Total training time: 1.1s\n",
      "INFO:tensorflow:Restoring parameters from ./Team06_HW3_2\n",
      "Final test accuracy: 50.52%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./Team06_HW2\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # predict the output for both train and valid set\n",
    "    hidden5_train = hidden5_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
    "    hidden5_valid = hidden5_out.eval(feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            h5_batch, y_batch = hidden5_train[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={hidden5_out: h5_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: hidden5_valid, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./Team06_HW3_2\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./Team06_HW3_2\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "### create a new softmax output layer on top of the 4th hidden layer\n",
    "### freeze all the layers except for the new output layer\n",
    "### test accuracy:0.58 (improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_outputs = 5\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./Team06_HW2.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"h4:0\")\n",
    "logits = tf.layers.dense(hidden4_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Team06_HW2\n",
      "0\tValidation loss: 2.064406\tBest loss: 2.064406\tAccuracy: 41.33%\n",
      "1\tValidation loss: 1.420861\tBest loss: 1.420861\tAccuracy: 50.00%\n",
      "2\tValidation loss: 1.235759\tBest loss: 1.235759\tAccuracy: 60.00%\n",
      "3\tValidation loss: 1.188183\tBest loss: 1.188183\tAccuracy: 57.33%\n",
      "4\tValidation loss: 1.089760\tBest loss: 1.089760\tAccuracy: 61.33%\n",
      "5\tValidation loss: 1.201103\tBest loss: 1.089760\tAccuracy: 59.33%\n",
      "6\tValidation loss: 1.104514\tBest loss: 1.089760\tAccuracy: 63.33%\n",
      "7\tValidation loss: 1.110676\tBest loss: 1.089760\tAccuracy: 60.67%\n",
      "8\tValidation loss: 1.191903\tBest loss: 1.089760\tAccuracy: 62.67%\n",
      "9\tValidation loss: 1.202659\tBest loss: 1.089760\tAccuracy: 62.00%\n",
      "10\tValidation loss: 1.152949\tBest loss: 1.089760\tAccuracy: 63.33%\n",
      "11\tValidation loss: 1.202276\tBest loss: 1.089760\tAccuracy: 62.00%\n",
      "12\tValidation loss: 1.121616\tBest loss: 1.089760\tAccuracy: 66.00%\n",
      "13\tValidation loss: 1.296584\tBest loss: 1.089760\tAccuracy: 61.33%\n",
      "14\tValidation loss: 1.147583\tBest loss: 1.089760\tAccuracy: 64.67%\n",
      "15\tValidation loss: 1.137294\tBest loss: 1.089760\tAccuracy: 65.33%\n",
      "16\tValidation loss: 1.236032\tBest loss: 1.089760\tAccuracy: 62.00%\n",
      "17\tValidation loss: 1.364651\tBest loss: 1.089760\tAccuracy: 61.33%\n",
      "18\tValidation loss: 1.182269\tBest loss: 1.089760\tAccuracy: 59.33%\n",
      "19\tValidation loss: 1.184031\tBest loss: 1.089760\tAccuracy: 63.33%\n",
      "20\tValidation loss: 1.209124\tBest loss: 1.089760\tAccuracy: 64.00%\n",
      "21\tValidation loss: 1.146226\tBest loss: 1.089760\tAccuracy: 66.67%\n",
      "22\tValidation loss: 1.257217\tBest loss: 1.089760\tAccuracy: 61.33%\n",
      "23\tValidation loss: 1.189462\tBest loss: 1.089760\tAccuracy: 62.67%\n",
      "24\tValidation loss: 1.248776\tBest loss: 1.089760\tAccuracy: 58.00%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./Team06_HW3_3\n",
      "Final test accuracy: 58.57%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./Team06_HW2\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./Team06_HW3_3\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./Team06_HW3_3\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "### unfreeze the top two hidden layers and continue training\n",
    "### test accuracy:0.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"h[34]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam3\")\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Team06_HW3_3\n",
      "0\tValidation loss: 1.241230\tBest loss: 1.241230\tAccuracy: 59.33%\n",
      "1\tValidation loss: 1.075959\tBest loss: 1.075959\tAccuracy: 64.00%\n",
      "2\tValidation loss: 1.114527\tBest loss: 1.075959\tAccuracy: 61.33%\n",
      "3\tValidation loss: 1.268440\tBest loss: 1.075959\tAccuracy: 55.33%\n",
      "4\tValidation loss: 1.149581\tBest loss: 1.075959\tAccuracy: 64.00%\n",
      "5\tValidation loss: 1.116969\tBest loss: 1.075959\tAccuracy: 65.33%\n",
      "6\tValidation loss: 1.203748\tBest loss: 1.075959\tAccuracy: 62.00%\n",
      "7\tValidation loss: 1.158077\tBest loss: 1.075959\tAccuracy: 61.33%\n",
      "8\tValidation loss: 1.241382\tBest loss: 1.075959\tAccuracy: 56.67%\n",
      "9\tValidation loss: 1.164335\tBest loss: 1.075959\tAccuracy: 64.00%\n",
      "10\tValidation loss: 1.193445\tBest loss: 1.075959\tAccuracy: 63.33%\n",
      "11\tValidation loss: 1.216349\tBest loss: 1.075959\tAccuracy: 58.00%\n",
      "12\tValidation loss: 1.245532\tBest loss: 1.075959\tAccuracy: 62.00%\n",
      "13\tValidation loss: 1.135479\tBest loss: 1.075959\tAccuracy: 66.67%\n",
      "14\tValidation loss: 1.165663\tBest loss: 1.075959\tAccuracy: 64.67%\n",
      "15\tValidation loss: 1.136601\tBest loss: 1.075959\tAccuracy: 64.67%\n",
      "16\tValidation loss: 1.184586\tBest loss: 1.075959\tAccuracy: 66.67%\n",
      "17\tValidation loss: 1.244507\tBest loss: 1.075959\tAccuracy: 63.33%\n",
      "18\tValidation loss: 1.186482\tBest loss: 1.075959\tAccuracy: 62.00%\n",
      "19\tValidation loss: 1.247395\tBest loss: 1.075959\tAccuracy: 64.67%\n",
      "20\tValidation loss: 1.180129\tBest loss: 1.075959\tAccuracy: 66.00%\n",
      "21\tValidation loss: 1.302542\tBest loss: 1.075959\tAccuracy: 61.33%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./Team06_HW3_4\n",
      "Final test accuracy: 59.02%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./Team06_HW3_3\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./Team06_HW3_4\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./Team06_HW3_4\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
